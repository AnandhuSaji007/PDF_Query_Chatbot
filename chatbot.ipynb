{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285bb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=(r\"C:\\Users\\WIIS\\Downloads\\SYSTEM SOFTWARE-Ktunotes.in.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c158aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0a550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Extract text from documents\n",
    "raw_texts = [doc.page_content for doc in pages]\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents(raw_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the embedding model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fa2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding and creating the vector store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(texts,embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5289053",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"filter\":{\"id\":\"1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Hugging Face model\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain_community.chat_models import ChatHuggingFace as CommunityChatHuggingFace\n",
    "from huggingface_hub import InferenceClient\n",
    "from langchain_huggingface.llms import HuggingFaceEndpoint\n",
    "\n",
    "HF_TOKEN=\"Your HF Token\"\n",
    "\n",
    "\n",
    "# Create endpoint LLM correctly\n",
    "llm_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.3,         \n",
    "    max_new_tokens=1024       \n",
    "\n",
    "# Wrap into chat model\n",
    "llm = ChatHuggingFace(llm=llm_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551fa9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "<|system|>>\n",
    "You are a helpful AI Assistant that follows instructions extremely well.\n",
    "Use the following context to answer user question.\n",
    "\n",
    "Think step by step before answering the question. You will get a $100 tip if you provide correct answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1d175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Create the prompt and output parser\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Define the chain (pipeline)\n",
    "chain = (\n",
    "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chain with a query\n",
    "print(chain.invoke(\"list the course outcomes\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
